package MOScene3D;

public class DepthTexture3D_New {
	// A depth texture is generated by pasting sprites at depths onto an output image of various resolutions and dimensions.
	// Sprites depths are recorded using a 16 bit grey-scale image. However, we should look at using a FloatImage here as well to preserve better results. 
	// The purpose of this class is to be able to further process this depth texture using 3D processes, such as lighting, convolving against depth and texturing in 3D.
	// Depth textures are initially generated using an original SceneData3D, either as a "master" (full extents of SceneData3D buffer) or as a ROI within that master. 
	
	// The Scenedata3D is of a fixed, relatively low resolution; when switching between master and ROI modes, the same depth data and camera data (distance from VP and FOV) is used to calculate 3D data, just with offsets. 
	// This means that SceneData3D is effectively resolution dependent in its 3D calculations.
	
	// This is very different from a DepthTexture3d,  which is of varying resolutions. This means that Depthtextures require a resolution independent way of determining 3D data. However, to create consistency of results between SceneData3D and 
	// DepthTextures, we should pass across the view data from the SceneData3D, such as master aspect ratio, camera and ROI data. This data is used to set up the 3D data interprestation in such a way as to crate consistency in 3D data between 
	// master and ROI 3D results and between ROIs.
	
	
	// This class reads in a depth texture, generated by a prior sprite pasting session
	
	// DEPTH DATA NOTE. Depth data should be real depth data, NOT normalised. So this probably requires passing over the real depth extrema for each ROI, so the depth data can be most faithfully recreated per ROI.
	// Viewing Application Rect is stored in Doc Space extents (i.e. longer edge is 1, shorter edge = 1/aspect)
	// ROI NOTE: All ROIS are stored as actual rects within the ViewingApplicationRect -  this makes for easy conversion between ROIDocSpace and ViewingAppRectDocSpace 
	//           ROIDocSpacePoint - > ROINormalisedSpacePoint ;  currentROI.lerp(LocalNormalisedSpacePoint) -> ViewingApplicationDocSpacePoint
	//
	
	// Data preserved from the SceneData3D
	// ViewingApplicationFullView - this is the full scene as viewed in the 3D viewing application, a crop is generated from this for pictorial reasons and preserved as.. 
	//								(data ViewingApplicationFullWidth and ViewingApplicationFullHeight as pixels, ViewingApplicationFOV - vertical FOV in pixels)
	// MasterView - The region of the OriginalFullView exported as a SceneData3D (MasterViewCropRect, Master View real depth extrema), 
	// ROIs - a collection of crops within the master view, current ROI. This can be stored parametrically as normalised Rects. There is a specific ROI used for a specific DepthTexture, the master uses (0,0,1,1); ROI real depth extrema
	
	// Data preserved in the new Depth Texture is depth per pixel including a special value for "no substance" (e.g. sky)
	
	// when a DepthTexture created the above data is combined, and a specific ROI is set.
	
	
	// The aim is to to be able to regenerate reliable, consistent 3D points across all ROIs and master of the  Given that the Depth Textures are of various resolutions we need a resolution indepndent way of determining the 
	// 3D coordinate for any point using Doc Space. Because orthogonal depth data is stored in the scene, Piranesi style 3D calculations will be used, not relient on vectore-inot-scene
	
	// Data calculated within the DepthTexture3D
	// Depth data is read back in and should be stored as original "real" depth 
	// CurrentFOV = proportion of ViewingApplicationFOV within the current ROI (vertical FOV) -  do we need this, as we are not calculating vectors into scene?
	// DistanceCameraToVP in ViewingAppDocSpace space is calculated by    
	//			((  (ViewingApplicationFullHeight/2)( tan(ViewingApplicationFOV/2)  )     /ViewingApplicationFullHeight   ) * ViewingApplicationHeightAspect     
	//			(is this tan(ViewingApplicationFOV/2)* ViewingApplicationHeightAspect     ?
	// 
	// This creates a normalised DistanceCameraToVP, however the depth values, which should be the original scene depth values
	
	
	// Eye space calculations follow. To calculate any 3D point for a Doc space point within the current ROI
	
	
	// realDepth = getRealDepth( localROIDocSpace );  
	

	// convert the localROIDocSpace space back into  ViewingApplicationDocSpace (  ROIDocSpacePoint - > ROINormalisedSpacePoint ;  currentROI.lerp(LocalNormalisedSpacePoint) -> ViewingApplicationDocSpacePoint   )
	// This gives viewingAppDocSpaceX, viewingAppDocSpaceY
	
	// convert this into "QuadrantSpace" (so  (0,0) is in the middle of the space, not top-left)
	// QuadrantSpaceX = viewingAppDocSpaceX - (ViewingApplicationWidthAspect/2)
	// QuadrantSpaceY = viewingAppDocSpaceY - (ViewingApplicationHeightAspect/2)
	
	// 3D points
	
	// Z = realDepth / ViewingApplicationFullHeight -> This gets the depth data into the same units as the DistanceCameraToVP
	// X = DistanceCameraToVP * windowQuadrantSpaceX/Z
	// Y = DistanceCameraToVP * windowQuadrantSpaceY/Z

}
